{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Xb9sN-A_X0-S"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9280ac8c34394bb39a8503aa8bda7b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_956560f635024976aac4b5e9713af139",
              "IPY_MODEL_0526aa06b1f44dc497f89da1711876f9",
              "IPY_MODEL_d6486ec9eff846d7a5c88ea7d60a9066",
              "IPY_MODEL_5854112e09fc473cacbc73f2f456ea7d"
            ],
            "layout": "IPY_MODEL_79b7b4a8cbec4e5ebac2763ed5393b40"
          }
        },
        "a98f3241295b44949419a47cf1aabd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34cda77283d4701a16c44f729c426de",
            "placeholder": "​",
            "style": "IPY_MODEL_2c4f4509bb874f7ab9267a2748d22f22",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3583f66f59d34f9aa091ac25c1a10659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bbb0a3e001974eb88cd785ae8e02b9a4",
            "placeholder": "​",
            "style": "IPY_MODEL_56b63877acf64baba23d4c1751221c6e",
            "value": ""
          }
        },
        "3bd062d1453646ad81a82799abd5dee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b224c088c82e40cda8d735239d9ba181",
            "style": "IPY_MODEL_7418df5d23ad4922abb7277331d83ca2",
            "value": true
          }
        },
        "094c44d0c80a4c8b9cf311cba744cb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a124cb3d0c0d4ba0a5772e9b9eb5fb66",
            "style": "IPY_MODEL_9b36e0db382c454ab850167d0c6a270b",
            "tooltip": ""
          }
        },
        "30998aeb98504f87bff439538158dc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1cc888fecda49d296e6c67b658c9476",
            "placeholder": "​",
            "style": "IPY_MODEL_d2e452ae670e4a01a31e0ee6f6d11209",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "79b7b4a8cbec4e5ebac2763ed5393b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c34cda77283d4701a16c44f729c426de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4f4509bb874f7ab9267a2748d22f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbb0a3e001974eb88cd785ae8e02b9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b63877acf64baba23d4c1751221c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b224c088c82e40cda8d735239d9ba181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7418df5d23ad4922abb7277331d83ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a124cb3d0c0d4ba0a5772e9b9eb5fb66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b36e0db382c454ab850167d0c6a270b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e1cc888fecda49d296e6c67b658c9476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e452ae670e4a01a31e0ee6f6d11209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe0c21999094580869da670c2abaf05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a67e3d13ef84080ad42f2e94a6d9cc3",
            "placeholder": "​",
            "style": "IPY_MODEL_3ee2c570aff0455f814e61e9a69c24d7",
            "value": "Connecting..."
          }
        },
        "9a67e3d13ef84080ad42f2e94a6d9cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee2c570aff0455f814e61e9a69c24d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "956560f635024976aac4b5e9713af139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593dad6104ff45c3966e6c59b67ad297",
            "placeholder": "​",
            "style": "IPY_MODEL_42b9f1e9576343038c6e37f2738486d4",
            "value": "Token is valid (permission: read)."
          }
        },
        "0526aa06b1f44dc497f89da1711876f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7985d9379b9d46069bc3478cd9897aaa",
            "placeholder": "​",
            "style": "IPY_MODEL_990f3759ec844a9f8e519ad9e57f7c33",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "d6486ec9eff846d7a5c88ea7d60a9066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfbaefb85fb84f2d8abaa446c95fdf2b",
            "placeholder": "​",
            "style": "IPY_MODEL_bafbc18bcbc04abfa180e0f28932ca35",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "5854112e09fc473cacbc73f2f456ea7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74bed67b2dcc4177a197b68e1f83eee0",
            "placeholder": "​",
            "style": "IPY_MODEL_ce0e8d0f53dc485b96fafea0d0be3b99",
            "value": "Login successful"
          }
        },
        "593dad6104ff45c3966e6c59b67ad297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b9f1e9576343038c6e37f2738486d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7985d9379b9d46069bc3478cd9897aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990f3759ec844a9f8e519ad9e57f7c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfbaefb85fb84f2d8abaa446c95fdf2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bafbc18bcbc04abfa180e0f28932ca35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74bed67b2dcc4177a197b68e1f83eee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0e8d0f53dc485b96fafea0d0be3b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tutsilianna/Automatic_Text_Processing_and_Image_Processing/blob/main/Greetings_and_Wishes_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xeq8pw1ms0H"
      },
      "source": [
        "# **Загрузка репозитория с проектом для получения данных**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2fc0R8Qm10p",
        "outputId": "2536fead-4c03-4199-9704-25795d35891e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Greetings_and_Wishes_Generator'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 49 (delta 18), reused 21 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (49/49), 12.82 MiB | 8.20 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/tutsilianna/Greetings_and_Wishes_Generator.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djpx8z8jm3PH"
      },
      "source": [
        "# **Подключение библиотек и гугл диска**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIc9oTqaMKFG"
      },
      "outputs": [],
      "source": [
        "# from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from IPython.display import clear_output\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import json\n",
        "import math\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "9280ac8c34394bb39a8503aa8bda7b55",
            "a98f3241295b44949419a47cf1aabd5c",
            "3583f66f59d34f9aa091ac25c1a10659",
            "3bd062d1453646ad81a82799abd5dee3",
            "094c44d0c80a4c8b9cf311cba744cb7f",
            "30998aeb98504f87bff439538158dc0e",
            "79b7b4a8cbec4e5ebac2763ed5393b40",
            "c34cda77283d4701a16c44f729c426de",
            "2c4f4509bb874f7ab9267a2748d22f22",
            "bbb0a3e001974eb88cd785ae8e02b9a4",
            "56b63877acf64baba23d4c1751221c6e",
            "b224c088c82e40cda8d735239d9ba181",
            "7418df5d23ad4922abb7277331d83ca2",
            "a124cb3d0c0d4ba0a5772e9b9eb5fb66",
            "9b36e0db382c454ab850167d0c6a270b",
            "e1cc888fecda49d296e6c67b658c9476",
            "d2e452ae670e4a01a31e0ee6f6d11209",
            "8fe0c21999094580869da670c2abaf05",
            "9a67e3d13ef84080ad42f2e94a6d9cc3",
            "3ee2c570aff0455f814e61e9a69c24d7",
            "956560f635024976aac4b5e9713af139",
            "0526aa06b1f44dc497f89da1711876f9",
            "d6486ec9eff846d7a5c88ea7d60a9066",
            "5854112e09fc473cacbc73f2f456ea7d",
            "593dad6104ff45c3966e6c59b67ad297",
            "42b9f1e9576343038c6e37f2738486d4",
            "7985d9379b9d46069bc3478cd9897aaa",
            "990f3759ec844a9f8e519ad9e57f7c33",
            "dfbaefb85fb84f2d8abaa446c95fdf2b",
            "bafbc18bcbc04abfa180e0f28932ca35",
            "74bed67b2dcc4177a197b68e1f83eee0",
            "ce0e8d0f53dc485b96fafea0d0be3b99"
          ],
          "height": 145
        },
        "id": "zZiz-PNFKHLq",
        "outputId": "6b6b4916-b7e9-4801-8dfe-1c664ab3fb1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9280ac8c34394bb39a8503aa8bda7b55"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxm4M6JbQoKB",
        "outputId": "37472951-f329-4fca-f24e-c81460f80125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb9sN-A_X0-S"
      },
      "source": [
        "# **Чтение и предобработка данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прочитаем данные, удалим дубликаты, пустые значения заполним пустыми строками."
      ],
      "metadata": {
        "id": "WXGcI3ga56w5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qxTwnvAKkvn",
        "outputId": "fd60405f-ca53-4f00-fd93-da84ce34dd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 27201 entries, 0 to 95219\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   text         27201 non-null  object\n",
            " 1   likes        27201 non-null  object\n",
            " 2   holiday      27201 non-null  object\n",
            " 3   to           27201 non-null  object\n",
            " 4   description  27201 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/Greetings_and_Wishes_Generator/data/raw/greetings.csv', encoding='utf-8')\n",
        "\n",
        "data.drop_duplicates(inplace=True)\n",
        "data.fillna('', inplace=True)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Удалим ненужные категории из стобца `holiday` - `Сценарии`, `Конкурсы`, `Розыгрыши`, `Извинения`, `Признания и предложения`."
      ],
      "metadata": {
        "id": "w6zRhDqN6HUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1tPa-OQ9Ng6",
        "outputId": "bb4dfd5c-1dc6-4a74-c5e4-ee23dbd17d63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "holiday\n",
              "На день рождения                  9150\n",
              "На праздники                      7356\n",
              "СМС                               3646\n",
              "Тосты                             2125\n",
              "На свадьбу                         938\n",
              "Ежедневные стихи                   899\n",
              "Важные события                     840\n",
              "По профессиям                      836\n",
              "На работу и учебу                  612\n",
              "Поздравления детей и для детей     200\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = data.loc[(data['holiday'] != \"Сценарии\") & (data['holiday'] != \"Конкурсы\") & (data['holiday'] != \"Розыгрыши\") & (data['holiday'] != \"Извинения\") & (data['holiday'] != \"Признания и предложения\")]\n",
        "\n",
        "data['holiday'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4vmkdb29_NH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babff104-67b5-4747-c7bd-855f322a847e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк в данных: 26602\n"
          ]
        }
      ],
      "source": [
        "print(\"Всего строк в данных: \" + str(len(data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данных в столбце  `text` в конце присутствует число, указывающее на количество лайков, оставленных пользователями, уберем его с помощью функции `remove_last_line_if_digits`\n",
        "\n"
      ],
      "metadata": {
        "id": "jreOPqKq9d21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CLQ0bs1bFRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2e4820-baf9-4c23-c3ac-f937f4edb059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4b596b72e315>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(remove_last_line_if_digits)\n",
            "<ipython-input-6-4b596b72e315>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].str.replace(r\"\\xao\", ' ')\n"
          ]
        }
      ],
      "source": [
        "def remove_last_line_if_digits(text):\n",
        "    lines = text.split('\\n')\n",
        "    last_line = lines[-1]\n",
        "    if last_line.isdigit():\n",
        "        return '\\n'.join(lines[:-1])\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "data['text'] = data['text'].apply(remove_last_line_if_digits)\n",
        "data['text'] = data['text'].str.replace(r\"\\xao\", ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzQdkqNhcvLG"
      },
      "source": [
        "# **Подготовка данных к обучению**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как данных много и обучение проводить тяжело в рамказ Colab, то возьмем только 1000 значений с поздравлениями \"На день рождения\""
      ],
      "metadata": {
        "id": "bFbDjEjY94Ze"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtkdO-9McFy9"
      },
      "outputs": [],
      "source": [
        "data_ = data.copy(deep=True)\n",
        "data_ = data_.loc[data_['holiday'] == 'На день рождения']\n",
        "data_ = data_.loc[data_['to'] != 'Happy Birthday Wishes']\n",
        "# data_ = data_[:1000]\n",
        "data_ = shuffle(data_)\n",
        "data_.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Представим данные в виде:\n",
        "#### **`<s>Ключевые слова: [праздник: ... ] [для кого: ... ] [описание: ... ] -> Поздравление: текст поздравления <\\s>`**,\n",
        "\n",
        "2) разделим на тренировочный и тестовый датасеты и запишем в соответствующие файлы."
      ],
      "metadata": {
        "id": "6qXHn-Y9-K9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_str_ = []\n",
        "for i in range(len(data_)):\n",
        "    item = f'<s>Ключевые слова: [Праздник: {data_.iloc[i][\"holiday\"]}]' + f'[Для кого: {data_.iloc[i][\"to\"]}]' + f'[Описание: {data_.iloc[i][\"description\"]}] ->\\n'\n",
        "    item += 'Поздравление: ' + data_.iloc[i]['text'] + '</s>'\n",
        "    if i < len(data) - 1:\n",
        "        item += '\\n\\n\\n'\n",
        "    data_str_.append(item)\n",
        "\n",
        "\n",
        "X, y = train_test_split(data_str_, test_size=0.2, random_state=42)\n",
        "\n",
        "with open('train.txt', 'w') as file:\n",
        "    for line in X:\n",
        "        file.write(line)\n",
        "\n",
        "with open('test.txt', 'w') as file:\n",
        "    for line in y:\n",
        "        file.write(line)"
      ],
      "metadata": {
        "id": "xqQcKXT0-I6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример получившихся данных"
      ],
      "metadata": {
        "id": "6f9D2DSA-QZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj6tfkW7WAyA",
        "outputId": "994da7d4-390e-4e8b-cbd4-2db6a736ab3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>Ключевые слова: [Праздник: На день рождения][Для кого: Сестре][Описание: Сестре от брата] ->\n",
            "Поздравление: С Днем Рождения, Любимая Сестренка,\n",
            "Поздравляю тебя искренне сейчас,\n",
            "Смейся ты всегда от счастья очень громко,\n",
            "Пусть исходит всегда блеск из твоих глаз.\n",
            "\n",
            "С Днем Рождения, Сестренка Дорогая,\n",
            "Никогда, тебя прошу, не унывай,\n",
            "Всё, о чем ты в своей жизни так мечтаешь,\n",
            "При желании малейшем, получай.\n",
            "\n",
            "В твоих мыслях, пусть, всегда будут идеи,\n",
            "Ты идеи все в реальность воплоти,\n",
            "Пусть любовь всегда твое сердечко греет,\n",
            "Будь любима ты и искренне люби.</s>\n"
          ]
        }
      ],
      "source": [
        "print(data_str_[50].strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Обучение `rugpt3small_bassed_on_grt2` по мануалу [RuGPT3FinetuneHF.ipynb](https://github.com/ai-forever/ru-gpts/blob/master/examples/RuGPT3FinetuneHF.ipynb)**"
      ],
      "metadata": {
        "id": "-3bPdUqvJS78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установка необходимых библиотек и скачивание скрипта `run_clm.py` для обучения"
      ],
      "metadata": {
        "id": "vtWPbBf7KqEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] accelerate -U\n",
        "!pip install datasets evaluate\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho3BeTF0JT7i",
        "outputId": "a0f70a0c-f91c-4f72-e039-e4677619d9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-d3864elg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-d3864elg\n",
            "  Resolved https://github.com/huggingface/transformers to commit 673440d073d5f534a6d6bedeeca94869afd8d0a7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.0.dev0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.42.0.dev0-py3-none-any.whl size=9105512 sha256=d2693c0ecceeed86580df6f9f4ff032cab54ec5edcbeb49f306e2455336de742\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-37ud6_ir/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.0\n",
            "    Uninstalling transformers-4.41.0:\n",
            "      Successfully uninstalled transformers-4.41.0\n",
            "Successfully installed transformers-4.42.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/language-modeling/run_clm.py -O /content/run_clm.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBE13yL6K4Jm",
        "outputId": "abe9de68-c2d9-4fcb-f1da-b557b46fbe15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-22 05:11:08--  https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/language-modeling/run_clm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28239 (28K) [text/plain]\n",
            "Saving to: ‘/content/run_clm.py’\n",
            "\n",
            "/content/run_clm.py 100%[===================>]  27.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-22 05:11:09 (144 MB/s) - ‘/content/run_clm.py’ saved [28239/28239]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запуск обучения модели, расположенной в `sberbank-ai/rugpt3small_based_on_gpt2`"
      ],
      "metadata": {
        "id": "4q41KbkEK7_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск обучения модели\n",
        "!python /content/run_clm.py \\\n",
        "    --model_name_or_path sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
        "    --train_file /content/train.txt \\\n",
        "    --validation_file /content/test.txt \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --block_size 256 \\\n",
        "    --dataset_config_name plain_text \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --output_dir /content/drive/MyDrive/model/essays"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTFoUmtaJyKC",
        "outputId": "8755c801-7c40-4b9c-b20b-e57af7f515a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-22 05:12:25.038367: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-22 05:12:25.038413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-22 05:12:25.231006: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-22 05:12:25.376502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-22 05:12:26.395522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/22/2024 05:12:31 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/22/2024 05:12:31 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/model/essays/runs/May22_05-12-31_b74af7d43521,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/model/essays,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/model/essays,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "Using custom data configuration default-6e799078ea3297b6\n",
            "05/22/2024 05:12:32 - INFO - datasets.builder - Using custom data configuration default-6e799078ea3297b6\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/text\n",
            "05/22/2024 05:12:32 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/text\n",
            "Generating dataset text (/root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101)\n",
            "05/22/2024 05:12:32 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101)\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101...\n",
            "05/22/2024 05:12:32 - INFO - datasets.builder - Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101...\n",
            "Downloading took 0.0 min\n",
            "05/22/2024 05:12:32 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "05/22/2024 05:12:32 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Generating train split\n",
            "05/22/2024 05:12:32 - INFO - datasets.builder - Generating train split\n",
            "Generating train split: 99735 examples [00:00, 1024217.02 examples/s]\n",
            "Generating validation split\n",
            "05/22/2024 05:12:32 - INFO - datasets.builder - Generating validation split\n",
            "Generating validation split: 25256 examples [00:00, 1747753.54 examples/s]\n",
            "Unable to verify splits sizes.\n",
            "05/22/2024 05:12:32 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101. Subsequent calls will reuse this data.\n",
            "05/22/2024 05:12:32 - INFO - datasets.builder - Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101. Subsequent calls will reuse this data.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 720/720 [00:00<00:00, 3.20MB/s]\n",
            "[INFO|configuration_utils.py:733] 2024-05-22 05:12:33,634 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/a9307e696cd3c5b7f953ff4cb19d76a4d81821d5/config.json\n",
            "[INFO|configuration_utils.py:800] 2024-05-22 05:12:33,635 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.42.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "tokenizer_config.json: 100% 1.25k/1.25k [00:00<00:00, 9.48MB/s]\n",
            "vocab.json: 100% 1.71M/1.71M [00:00<00:00, 3.71MB/s]\n",
            "merges.txt: 100% 1.27M/1.27M [00:00<00:00, 44.8MB/s]\n",
            "special_tokens_map.json: 100% 574/574 [00:00<00:00, 4.22MB/s]\n",
            "[INFO|tokenization_utils_base.py:2109] 2024-05-22 05:12:38,341 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/a9307e696cd3c5b7f953ff4cb19d76a4d81821d5/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2109] 2024-05-22 05:12:38,341 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/a9307e696cd3c5b7f953ff4cb19d76a4d81821d5/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2109] 2024-05-22 05:12:38,341 >> loading file tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2109] 2024-05-22 05:12:38,341 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2109] 2024-05-22 05:12:38,341 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/a9307e696cd3c5b7f953ff4cb19d76a4d81821d5/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2109] 2024-05-22 05:12:38,341 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/a9307e696cd3c5b7f953ff4cb19d76a4d81821d5/tokenizer_config.json\n",
            "pytorch_model.bin: 100% 551M/551M [00:02<00:00, 202MB/s]\n",
            "[INFO|modeling_utils.py:3474] 2024-05-22 05:12:44,218 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/a9307e696cd3c5b7f953ff4cb19d76a4d81821d5/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:962] 2024-05-22 05:12:44,784 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:4280] 2024-05-22 05:12:45,345 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:4288] 2024-05-22 05:12:45,345 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|modeling_utils.py:3797] 2024-05-22 05:12:45,864 >> Generation config file not found, using a generation config created from the model config.\n",
            "Running tokenizer on dataset:   0% 0/99735 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-03f00b6a03bce883.arrow\n",
            "05/22/2024 05:12:45 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-03f00b6a03bce883.arrow\n",
            "Running tokenizer on dataset: 100% 99735/99735 [00:03<00:00, 26641.93 examples/s]\n",
            "Running tokenizer on dataset:   0% 0/25256 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-2eff54d46cc610dd.arrow\n",
            "05/22/2024 05:12:49 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-2eff54d46cc610dd.arrow\n",
            "Running tokenizer on dataset: 100% 25256/25256 [00:01<00:00, 23575.64 examples/s]\n",
            "Grouping texts in chunks of 256:   0% 0/99735 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-1ad2e59291dc7f17.arrow\n",
            "05/22/2024 05:12:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-1ad2e59291dc7f17.arrow\n",
            "Grouping texts in chunks of 256: 100% 99735/99735 [00:01<00:00, 66903.20 examples/s]\n",
            "Grouping texts in chunks of 256:   0% 0/25256 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-fd4d50f47b1845a7.arrow\n",
            "05/22/2024 05:12:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-6e799078ea3297b6/0.0.0/96636a050ef51804b84abbfd4f4ad440e01153c24b86293eb5c3b300a41f9101/cache-fd4d50f47b1845a7.arrow\n",
            "Grouping texts in chunks of 256: 100% 25256/25256 [00:00<00:00, 68099.18 examples/s]\n",
            "Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 18.9MB/s]\n",
            "[INFO|trainer.py:2108] 2024-05-22 05:12:54,763 >> ***** Running training *****\n",
            "[INFO|trainer.py:2109] 2024-05-22 05:12:54,763 >>   Num examples = 3,595\n",
            "[INFO|trainer.py:2110] 2024-05-22 05:12:54,763 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2111] 2024-05-22 05:12:54,763 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:2114] 2024-05-22 05:12:54,763 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:2115] 2024-05-22 05:12:54,763 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2116] 2024-05-22 05:12:54,763 >>   Total optimization steps = 10,785\n",
            "[INFO|trainer.py:2117] 2024-05-22 05:12:54,764 >>   Number of trainable parameters = 125,231,616\n",
            "{'loss': 2.3814, 'grad_norm': 4.000997066497803, 'learning_rate': 4.7681965693092264e-05, 'epoch': 0.14}\n",
            "  5% 500/10785 [00:59<20:32,  8.35it/s][INFO|trainer.py:3444] 2024-05-22 05:13:54,564 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:13:54,573 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:13:54,582 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:13:58,859 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:13:58,865 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:13:58,872 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 2.2247, 'grad_norm': 4.373688697814941, 'learning_rate': 4.536393138618452e-05, 'epoch': 0.28}\n",
            "  9% 1000/10785 [02:10<20:05,  8.12it/s][INFO|trainer.py:3444] 2024-05-22 05:15:05,666 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-1000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:15:05,674 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-1000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:15:05,682 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-1000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:15:08,013 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-1000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:15:08,020 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:15:08,026 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 2.2019, 'grad_norm': 4.057775974273682, 'learning_rate': 4.3045897079276774e-05, 'epoch': 0.42}\n",
            " 14% 1500/10785 [03:18<18:22,  8.42it/s][INFO|trainer.py:3444] 2024-05-22 05:16:13,676 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-1500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:16:13,687 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-1500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:16:13,700 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-1500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:16:15,647 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-1500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:16:15,655 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:16:15,661 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 2.1461, 'grad_norm': 4.028141975402832, 'learning_rate': 4.0727862772369036e-05, 'epoch': 0.56}\n",
            " 19% 2000/10785 [04:28<17:20,  8.45it/s][INFO|trainer.py:3444] 2024-05-22 05:17:22,841 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-2000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:17:22,850 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-2000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:17:22,856 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-2000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:17:24,814 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-2000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:17:24,827 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:17:24,834 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-2000/special_tokens_map.json\n",
            "{'loss': 2.0949, 'grad_norm': 3.6023190021514893, 'learning_rate': 3.840982846546129e-05, 'epoch': 0.7}\n",
            " 23% 2500/10785 [05:36<16:46,  8.23it/s][INFO|trainer.py:3444] 2024-05-22 05:18:30,835 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-2500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:18:30,844 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-2500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:18:30,850 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-2500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:18:33,075 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-2500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:18:33,081 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:18:33,086 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-2500/special_tokens_map.json\n",
            "{'loss': 2.0732, 'grad_norm': 2.834366798400879, 'learning_rate': 3.609179415855355e-05, 'epoch': 0.83}\n",
            " 28% 3000/10785 [06:45<15:28,  8.39it/s][INFO|trainer.py:3444] 2024-05-22 05:19:40,585 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-3000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:19:40,594 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-3000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:19:40,604 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-3000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:19:43,336 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-3000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:19:43,353 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:19:43,365 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-3000/special_tokens_map.json\n",
            "{'loss': 2.0569, 'grad_norm': 3.208677291870117, 'learning_rate': 3.377375985164581e-05, 'epoch': 0.97}\n",
            " 32% 3500/10785 [07:54<14:43,  8.25it/s][INFO|trainer.py:3444] 2024-05-22 05:20:49,567 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-3500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:20:49,574 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-3500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:20:49,580 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-3500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:20:51,572 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-3500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:20:51,585 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-3500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:20:51,601 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-3500/special_tokens_map.json\n",
            "{'loss': 1.8239, 'grad_norm': 3.604637861251831, 'learning_rate': 3.145572554473806e-05, 'epoch': 1.11}\n",
            " 37% 4000/10785 [09:08<13:37,  8.30it/s][INFO|trainer.py:3444] 2024-05-22 05:22:03,005 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-4000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:22:03,015 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-4000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:22:03,030 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-4000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:22:04,913 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-4000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:22:04,920 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-4000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:22:04,926 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-4000/special_tokens_map.json\n",
            "{'loss': 1.8045, 'grad_norm': 4.285064697265625, 'learning_rate': 2.9137691237830324e-05, 'epoch': 1.25}\n",
            " 42% 4500/10785 [10:16<12:21,  8.47it/s][INFO|trainer.py:3444] 2024-05-22 05:23:11,771 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-4500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:23:11,778 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-4500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:23:11,784 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-4500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:23:15,759 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-4500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:23:15,765 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-4500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:23:15,771 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-4500/special_tokens_map.json\n",
            "{'loss': 1.7942, 'grad_norm': 4.307316303253174, 'learning_rate': 2.6819656930922575e-05, 'epoch': 1.39}\n",
            " 46% 5000/10785 [11:26<11:42,  8.24it/s][INFO|trainer.py:3444] 2024-05-22 05:24:21,038 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-5000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:24:21,045 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-5000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:24:21,051 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-5000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:24:23,303 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-5000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:24:23,321 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-5000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:24:23,328 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-5000/special_tokens_map.json\n",
            "{'loss': 1.7971, 'grad_norm': 4.8639235496521, 'learning_rate': 2.4501622624014837e-05, 'epoch': 1.53}\n",
            " 51% 5500/10785 [12:36<10:23,  8.47it/s][INFO|trainer.py:3444] 2024-05-22 05:25:30,851 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-5500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:25:30,858 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-5500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:25:30,867 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-5500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:25:32,837 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-5500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:25:32,851 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-5500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:25:32,858 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-5500/special_tokens_map.json\n",
            "{'loss': 1.7853, 'grad_norm': 3.4696781635284424, 'learning_rate': 2.218358831710709e-05, 'epoch': 1.67}\n",
            " 56% 6000/10785 [13:44<09:23,  8.49it/s][INFO|trainer.py:3444] 2024-05-22 05:26:39,694 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-6000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:26:39,700 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-6000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:26:39,706 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-6000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:26:41,679 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-6000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:26:41,686 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-6000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:26:41,692 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-6000/special_tokens_map.json\n",
            "{'loss': 1.7676, 'grad_norm': 3.39569354057312, 'learning_rate': 1.9865554010199353e-05, 'epoch': 1.81}\n",
            " 60% 6500/10785 [14:51<08:53,  8.04it/s][INFO|trainer.py:3444] 2024-05-22 05:27:46,769 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-6500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:27:46,778 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-6500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:27:46,784 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-6500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:27:49,180 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-6500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:27:49,187 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-6500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:27:49,193 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-6500/special_tokens_map.json\n",
            "{'loss': 1.7892, 'grad_norm': 4.299607753753662, 'learning_rate': 1.7547519703291608e-05, 'epoch': 1.95}\n",
            " 65% 7000/10785 [16:00<07:25,  8.49it/s][INFO|trainer.py:3444] 2024-05-22 05:28:54,941 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-7000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:28:54,947 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-7000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:28:54,954 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-7000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:28:56,876 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-7000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:28:56,883 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-7000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:28:56,888 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-7000/special_tokens_map.json\n",
            "{'loss': 1.646, 'grad_norm': 3.412705421447754, 'learning_rate': 1.5229485396383866e-05, 'epoch': 2.09}\n",
            " 70% 7500/10785 [17:08<06:35,  8.31it/s][INFO|trainer.py:3444] 2024-05-22 05:30:02,987 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-7500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:30:02,994 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-7500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:30:03,000 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-7500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:30:05,001 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-7500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:30:05,008 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-7500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:30:05,014 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-7500/special_tokens_map.json\n",
            "{'loss': 1.5709, 'grad_norm': 4.345050811767578, 'learning_rate': 1.2911451089476126e-05, 'epoch': 2.23}\n",
            " 74% 8000/10785 [18:18<06:05,  7.62it/s][INFO|trainer.py:3444] 2024-05-22 05:31:12,972 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-8000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:31:12,993 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-8000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:31:13,021 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-8000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:31:15,374 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-8000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:31:15,380 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-8000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:31:16,139 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-8000/special_tokens_map.json\n",
            "{'loss': 1.5518, 'grad_norm': 3.5202982425689697, 'learning_rate': 1.0593416782568383e-05, 'epoch': 2.36}\n",
            " 79% 8500/10785 [19:30<07:16,  5.23it/s][INFO|trainer.py:3444] 2024-05-22 05:32:25,012 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-8500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:32:25,020 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-8500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:32:25,026 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-8500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:32:33,218 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-8500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:32:33,227 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-8500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:32:33,233 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-8500/special_tokens_map.json\n",
            "{'loss': 1.6062, 'grad_norm': 5.1500244140625, 'learning_rate': 8.27538247566064e-06, 'epoch': 2.5}\n",
            " 83% 9000/10785 [21:01<03:47,  7.86it/s][INFO|trainer.py:3444] 2024-05-22 05:33:56,011 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-9000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:33:56,020 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-9000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:33:56,027 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-9000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:33:58,951 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-9000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:33:58,982 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-9000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:33:59,002 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-9000/special_tokens_map.json\n",
            "{'loss': 1.5992, 'grad_norm': 4.336660385131836, 'learning_rate': 5.957348168752898e-06, 'epoch': 2.64}\n",
            " 88% 9500/10785 [22:17<02:38,  8.11it/s][INFO|trainer.py:3444] 2024-05-22 05:35:11,878 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-9500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:35:11,887 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-9500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:35:11,896 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-9500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:35:14,296 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-9500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:35:14,303 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-9500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:35:14,307 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-9500/special_tokens_map.json\n",
            "{'loss': 1.5521, 'grad_norm': 3.796273708343506, 'learning_rate': 3.6393138618451553e-06, 'epoch': 2.78}\n",
            " 93% 10000/10785 [23:32<01:38,  8.00it/s][INFO|trainer.py:3444] 2024-05-22 05:36:26,837 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-10000\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:36:26,847 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-10000/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:36:26,856 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-10000/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:36:32,632 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-10000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:36:32,644 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-10000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:36:32,657 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-10000/special_tokens_map.json\n",
            "{'loss': 1.5792, 'grad_norm': 4.135786056518555, 'learning_rate': 1.3212795549374132e-06, 'epoch': 2.92}\n",
            " 97% 10500/10785 [25:00<00:34,  8.33it/s][INFO|trainer.py:3444] 2024-05-22 05:37:55,248 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-10500\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:37:55,259 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-10500/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:37:55,264 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-10500/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:37:57,820 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-10500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:37:57,829 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-10500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:37:57,835 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-10500/special_tokens_map.json\n",
            "100% 10785/10785 [25:41<00:00,  8.18it/s][INFO|trainer.py:3444] 2024-05-22 05:38:36,387 >> Saving model checkpoint to /content/drive/MyDrive/model/essays/checkpoint-10785\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:38:36,394 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-10785/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:38:36,400 >> Configuration saved in /content/drive/MyDrive/model/essays/checkpoint-10785/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:38:43,789 >> Model weights saved in /content/drive/MyDrive/model/essays/checkpoint-10785/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:38:43,795 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/checkpoint-10785/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:38:43,808 >> Special tokens file saved in /content/drive/MyDrive/model/essays/checkpoint-10785/special_tokens_map.json\n",
            "[INFO|trainer.py:2358] 2024-05-22 05:38:52,210 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1557.447, 'train_samples_per_second': 6.925, 'train_steps_per_second': 6.925, 'train_loss': 1.8419307873212578, 'epoch': 3.0}\n",
            "100% 10785/10785 [25:57<00:00,  6.92it/s]\n",
            "[INFO|trainer.py:3444] 2024-05-22 05:38:52,251 >> Saving model checkpoint to /content/drive/MyDrive/model/essays\n",
            "[INFO|configuration_utils.py:472] 2024-05-22 05:38:52,259 >> Configuration saved in /content/drive/MyDrive/model/essays/config.json\n",
            "[INFO|configuration_utils.py:731] 2024-05-22 05:38:52,273 >> Configuration saved in /content/drive/MyDrive/model/essays/generation_config.json\n",
            "[INFO|modeling_utils.py:2618] 2024-05-22 05:38:54,838 >> Model weights saved in /content/drive/MyDrive/model/essays/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2519] 2024-05-22 05:38:54,844 >> tokenizer config file saved in /content/drive/MyDrive/model/essays/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2528] 2024-05-22 05:38:54,850 >> Special tokens file saved in /content/drive/MyDrive/model/essays/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  total_flos               =  1312249GF\n",
            "  train_loss               =     1.8419\n",
            "  train_runtime            = 0:25:57.44\n",
            "  train_samples            =       3595\n",
            "  train_samples_per_second =      6.925\n",
            "  train_steps_per_second   =      6.925\n",
            "05/22/2024 05:38:55 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:3753] 2024-05-22 05:38:55,459 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3755] 2024-05-22 05:38:55,459 >>   Num examples = 913\n",
            "[INFO|trainer.py:3758] 2024-05-22 05:38:55,459 >>   Batch size = 1\n",
            "100% 913/913 [00:23<00:00, 38.88it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.6166\n",
            "  eval_loss               =      1.971\n",
            "  eval_runtime            = 0:00:23.57\n",
            "  eval_samples            =        913\n",
            "  eval_samples_per_second =     38.734\n",
            "  eval_steps_per_second   =     38.734\n",
            "  perplexity              =     7.1779\n",
            "[INFO|modelcard.py:449] 2024-05-22 05:39:19,681 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6165582114554474}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "rfL5T98eKIqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка обученной модели и токенизатора"
      ],
      "metadata": {
        "id": "CBijaqrILJ9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model     = GPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/model/essays').to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('/content/drive/MyDrive/model/essays') #('sberbank-ai/rugpt3small_based_on_gpt2')"
      ],
      "metadata": {
        "id": "S2bVGSW3J8gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Установка фиксированных зерен для воспроизводимости\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Перемещение модели на GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUVg1kwRKC9b",
        "outputId": "7819ed43-e625-40f5-9f29-0ca96d72173e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50264, 768)\n",
              "    (wpe): Embedding(2048, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Текст для генерации\n",
        "text = '<s>Ключевые слова: [Праздник: На день рождения][Для кого: Дочери][Описание: Дочери на 45 лет] ->\\nПоздравление:'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "\n",
        "# Генерация текста\n",
        "output = model.generate(input_ids.cuda(), max_length=500, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1)\n",
        "\n",
        "# Декодирование сгенерированных токенов в текст\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X94urOzYfAcB",
        "outputId": "ddd96711-fded-421c-971c-b71b8bce284f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ключевые слова: [Праздник: На день рождения][Для кого: Дочери][Описание: Дочери на 45 лет] ->\n",
            "Поздравление: Я поздравляю с днем рожденья тебя, Дочка моя. Сорок пять тебе сегодня исполняется твоей судьбе и я хочу пожелать в этот праздник всего самого прекрасного из того,чего ты сама себе пожелаешь.Пусть всегда твои сбываются желания! И пусть все то о чем мечтается будет именно так как хочешь!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Вычисление перплексии и косинусного сходства**"
      ],
      "metadata": {
        "id": "SF9XO1syL4Sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим список с промтами, эталонными и сгенерированными текстами"
      ],
      "metadata": {
        "id": "VNJTtGcYi9P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y[0].split('->\\nПоздравление: ')[-1]\n",
        "\n",
        "promts = [ item.split('->\\nПоздравление: ')[0] + '->\\nПоздравление:'  for item in y]\n",
        "reference_texts = [item.split('->\\nПоздравление: ')[-1] for item in y]\n",
        "generated_texts = []\n",
        "\n",
        "for promt in promts:\n",
        "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(input_ids.cuda(),\n",
        "                            max_length=500,\n",
        "                            repetition_penalty=5.0,\n",
        "                            do_sample=True,\n",
        "                            top_k=5,\n",
        "                            top_p=0.95,\n",
        "                            temperature=1)\n",
        "\n",
        "    generated_texts.append(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "I3HtNo7ShEIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_texts_split = [item.split('->\\nПоздравление: ')[-1] for item in generated_texts]"
      ],
      "metadata": {
        "id": "qMaX2jjR8w2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('generated_texts.txt', 'w') as file:\n",
        "    for x in generated_texts_split:\n",
        "        file.write(x)"
      ],
      "metadata": {
        "id": "YZZKJqlusyfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('generated_texts.txt', 'r') as file:\n",
        "   generated_text = file.readlines()\n",
        "\n",
        "generated_text[:2]"
      ],
      "metadata": {
        "id": "TfNqpfyLrI0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_texts(tokenizer, texts, model):\n",
        "    encodings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "        inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states[-1]                     # Последний слой скрытых состояний\n",
        "        encodings.append(hidden_states[0].mean(dim=0).cpu().numpy())  # Среднее по всем токенам\n",
        "    return np.vstack(encodings)\n",
        "\n",
        "def evaluate_cosine_similarity(model, tokenizer, reference_texts, generated_texts):\n",
        "    reference_encodings = encode_texts(tokenizer, reference_texts, model)\n",
        "    generated_encodings = encode_texts(tokenizer, generated_texts, model)\n",
        "    similarities = cosine_similarity(reference_encodings, generated_encodings)\n",
        "    avg_similarity = np.mean(np.diag(similarities))\n",
        "    return avg_similarity\n",
        "\n",
        "cosine_similarity_score = evaluate_cosine_similarity(model, tokenizer, reference_texts, generated_texts_split)\n",
        "print(f\"Cosine Similarity: {cosine_similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR8l3u0jMScY",
        "outputId": "588b429e-4594-43c5-fc4d-8e871273dd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.6579082608222961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ вычисление перплексии ------\n",
        "def evaluate_perplexity(model, eval_dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        inputs, labels = (batch, batch)\n",
        "        inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    avg_loss = total_loss / nb_eval_steps\n",
        "    perplexity = math.exp(avg_loss)\n",
        "    return perplexity\n",
        "\n",
        "test_dataset = load_dataset(tokenizer, 'path_to_test_data.txt', block_size=512)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
        "\n",
        "# Вычисление перплексии\n",
        "perplexity = evaluate_perplexity(model, test_dataloader)\n",
        "print(f\"Perplexity: {perplexity}\")"
      ],
      "metadata": {
        "id": "NWnNUrY0LyT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, file_path, block_size=512):\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            lines = file.readlines()\n",
        "        self.examples = []\n",
        "        for line in lines:\n",
        "            tokenized_text = tokenizer.encode(line, add_special_tokens=True, truncation=True, max_length=block_size)\n",
        "            self.examples.append(tokenized_text)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.tensor(self.examples[i], dtype=torch.long)\n",
        "\n",
        "def load_dataset(tokenizer, file_path, block_size=512):\n",
        "    return TextDataset(tokenizer, file_path, block_size)\n",
        "\n",
        "\n",
        "# Путь к тестовым данным\n",
        "test_data_path = '/content/test.txt'\n",
        "\n",
        "# Загрузка и подготовка тестовых данных\n",
        "test_dataset = load_dataset(tokenizer, test_data_path, block_size=512)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
        "\n",
        "# Функция для вычисления перплексии\n",
        "def evaluate_perplexity(model, eval_dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        inputs, labels = batch, batch\n",
        "        inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    avg_loss = total_loss / nb_eval_steps\n",
        "    perplexity = math.exp(avg_loss)\n",
        "    return perplexity\n",
        "\n",
        "# Вычисление перплексии\n",
        "perplexity = evaluate_perplexity(model, test_dataloader)\n",
        "print(f\"Perplexity: {perplexity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkWoyKUn_AFD",
        "outputId": "3f2c839d-6599-4343-b564-e6c28048482c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пути для сохранения модели и токенизатора\n",
        "output_dir = '/content/drive/MyDrive/model/esesays'\n",
        "\n",
        "# Сохранение дообученной модели\n",
        "model.save_pretrained(output_dir)\n",
        "\n",
        "# Сохранение токенизатора\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Модель и токенизатор сохранены в {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR5z45Tn_Zys",
        "outputId": "c941ee62-a1b2-494f-eab3-d30daae9fbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель и токенизатор сохранены в /content/drive/MyDrive/model/esesays\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = '/content/drive/MyDrive/model/esesays'\n",
        "\n",
        "model_new     = GPT2LMHeadModel.from_pretrained(output_dir).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer_new = GPT2Tokenizer.from_pretrained(output_dir) #('sberbank-ai/rugpt3small_based_on_gpt2')"
      ],
      "metadata": {
        "id": "GMxIEgpRFt6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Текст для генерации\n",
        "text = '<s>Ключевые слова: [Праздник: На день рождения][Для кого: Сыну][Описание: Сыну на 45 лет] ->\\nПоздравление:'\n",
        "input_ids = tokenizer_new.encode(text, return_tensors='pt')\n",
        "\n",
        "# Генерация текста\n",
        "output = model_new.generate(input_ids.cuda(), max_length=256, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1)\n",
        "\n",
        "# Декодирование сгенерированных токенов в текст\n",
        "generated_text = tokenizer_new.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t0FJFjxF-Jg",
        "outputId": "79a8d366-5545-4106-b005-46e9b671d857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ключевые слова: [Праздник: На день рождения][Для кого: Сыну][Описание: Сыну на 45 лет] ->\n",
            "Поздравление: Я поздравляю с днем рожденья тебя, Сын. Сорок пять тебе исполнилось сегодня и ты уже мужчина большой в душе своей сохрани тепло свое о тех днях что были когда то безвозвратно унесены тобой из прошлого чтобы не вспоминать их вновь возвращаясь к ним снова возвращаясь опять вспоминая.ты вспоминал все те дни которые могли быть лучше если бы они оставались прежними! И вот сейчас я хочу пожелать,чтобы тот миг который остался у твоей двери стал для всех возможным или почти бесконечным!!! Чтобы каждый новый год мог становиться только еще прекрасней... Пусть твой дом будет полон самых приятных сюрпризов от людей вокруг него.... пусть он станет полной чашей!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Использование дообученной модели**"
      ],
      "metadata": {
        "id": "D_AbCWSDtOOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "PYN2TncMtRoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_model = '/content/drive/MyDrive/model/essays'"
      ],
      "metadata": {
        "id": "T40QOEF5tk05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model     = GPT2LMHeadModel.from_pretrained(path_to_model).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(path_to_model)"
      ],
      "metadata": {
        "id": "cN3s18wrtjix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "holiday = 'На день рождения' # input()\n",
        "to = input()\n",
        "description = input()\n",
        "\n",
        "# Текст для генерации\n",
        "text = f'<s>Ключевые слова: [Праздник: {holiday}][Для кого: {to}][Описание: {description}] ->\\nПоздравление:'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "\n",
        "# Генерация текста\n",
        "output = model.generate(input_ids.cuda(), max_length=256, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1)\n",
        "\n",
        "# Декодирование сгенерированных токенов в текст\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "Y8pHc7gstiyC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}