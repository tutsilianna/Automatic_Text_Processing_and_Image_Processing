{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tutsilianna/Automatic_Text_Processing_and_Image_Processing/blob/main/Computer%20Vision/photos/Task_6_%7C_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoIkUK-XhTHI"
      },
      "source": [
        "ImageAI : Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljc5Zd4HhTHK"
      },
      "source": [
        "Library ImageAI provides very convinient and powerful methods to detect objects in the image. In order to start detecting objects the trained models should be uploaded. We will use two models, i.e. RetinaNet and YOLO and compare them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clXK7VfehTHM"
      },
      "source": [
        "To get started we istall computer vision library OpenCV, and the library ImageAI that allows to detect objects in the image, and the library of machine learning TensorFlow and a neuronet library Keras of the specified release :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUW2TCTihTHL",
        "outputId": "a3e4eaaa-6db4-43e4-b251-49bcabc14a57"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "!pip install -q tensorflow==2.3.1\n",
        "!pip install -q tensorflow-gpu==2.3.1\n",
        "!git clone https://github.com/dvolchek/YOLOv3-TensorFlow-2.x.git\n",
        "%cd YOLOv3-TensorFlow-2.x\n",
        "!wget -P model_data https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.1 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.3.1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.3.1 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-gpu==2.3.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'YOLOv3-TensorFlow-2.x'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 81 (delta 24), reused 48 (delta 18), pack-reused 26\u001b[K\n",
            "Receiving objects: 100% (81/81), 42.11 MiB | 31.54 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "/content/YOLOv3-TensorFlow-2.x\n",
            "--2024-05-07 12:37:28--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘model_data/yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  35.0MB/s    in 7.6s    \n",
            "\n",
            "2024-05-07 12:39:16 (31.2 MB/s) - ‘model_data/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpQGKiguhTHN"
      },
      "source": [
        "import detection_demo\n",
        "from PIL import Image\n",
        "\n",
        "TP, TN, FP, FN = [], [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Legend:**\n",
        "\n",
        "* TP (True Positive) — the object is correctly classified (i.e. the expert and classifier opinions are the same);\n",
        "* TN (True Negative) — set this value to zero as there are many objects in the images (not only people), ;\n",
        "* FP (False Positive) — the classifier evaluates the selected object as a person, but the expert disagrees;\n",
        "* FN (False Negative) — the expert classifies the selected object as a person, but the classifier doesn’t.\n",
        "\n",
        "**Example 1:** There are four persons in the photo. The classifier finds three persons, therefore, TP=3, FN=1, FP=0, TN=0.\n",
        "\n",
        "**Example 2:** There are four persons in the photo. The classifier finds six persons (it classifies a bush and traffic light as persons). Thus, TP=4, FP=2, FN=0, TN=0.\n",
        "\n",
        "**IMPORTANT NOTE:** If a blue rectangle is drawn around several persons (the frame is big enough and there are several persons in it), you should count the number of items found by the classifier (TP), i.e. the number of blue rectangles drawn by the classifier and the number of persons not foudnd (FN)."
      ],
      "metadata": {
        "id": "e1YF8-JE83IO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW1Lu_YShTHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e630b060-17f9-4358-91d6-b5a774187bc7"
      },
      "source": [
        "detection_demo.detect('/content/photos/1.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image can be viewed in the project folder, or displayed on the screen in notebook.\n",
        "It can be seen that there are 5 people in the image. The model successfully coped with their detection. Other objects like laptop, cup, etc. are not of interest to us)"
      ],
      "metadata": {
        "id": "Np-DfzubKWpB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAfO4iMYhTHR"
      },
      "source": [
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWp9ii4qhTHS"
      },
      "source": [
        "TP.append(3)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/2.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "g7911fGL_CUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(4)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(0)"
      ],
      "metadata": {
        "id": "sHzNi_zV_PRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/3.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "RAqgkuRr_cRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(3)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(2)"
      ],
      "metadata": {
        "id": "xOPgKZa2_odS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/4.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "f804S7Mk_6Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(6)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(0)"
      ],
      "metadata": {
        "id": "IrNZnopV_8IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/5.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "C1CO6vJy_98p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(5)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(0)"
      ],
      "metadata": {
        "id": "TfwrLPol_98q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/6.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "IAZmef7yAD_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(5)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(1)"
      ],
      "metadata": {
        "id": "7iFxdHMpAExr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/7.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "_92HV_g_AExr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(3)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(0)"
      ],
      "metadata": {
        "id": "WxjlUMBiAD_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/8.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "UVxejBwkAGVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(3)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(1)"
      ],
      "metadata": {
        "id": "iS1gBX8xAGVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/9.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "7TlQNYWYAHG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(4)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(1)"
      ],
      "metadata": {
        "id": "nLj8XrnVAHG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_demo.detect('/content/photos/10.jpg')\n",
        "image = Image.open('/content/detected.jpg')\n",
        "image"
      ],
      "metadata": {
        "id": "Ny8vkLtYAIDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TP.append(6)\n",
        "TN.append(0)\n",
        "FP.append(0)\n",
        "FN.append(1)"
      ],
      "metadata": {
        "id": "G-1DjytEAIDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(TP), sum(FP))\n",
        "print(sum(FN), sum(TN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XYaeTyHCA0w",
        "outputId": "d6abdbc6-0829-42c3-cd8c-e217814c2d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 0\n",
            "7 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$F_1 = 2 * \\frac{\\text{precision} * \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
        "\n",
        "\n",
        "$$\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}},    \\;\\; \\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$"
      ],
      "metadata": {
        "id": "lZsS7p_uCxSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision = sum(TP) / (sum(TP) + sum(FP))\n",
        "recall = sum(TP) / (sum(TP) + sum(FN))\n",
        "\n",
        "F_1 = 2 * (precision*recall) / (precision+recall)\n",
        "\n",
        "print('precision=', precision)\n",
        "print('recall=', recall)\n",
        "print('F_1=', round(F_1, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-npo9eLUDVjp",
        "outputId": "704064d7-b346-4d36-972a-04c068150040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision= 1.0\n",
            "recall= 0.8571428571428571\n",
            "F_1= 0.923\n"
          ]
        }
      ]
    }
  ]
}